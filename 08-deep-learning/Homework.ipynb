{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b198b71-c907-4847-9ccf-36a262c23b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.9.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.24.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (1.24.4)\n",
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting filelock (from torch)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.11/site-packages (from torch) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/conda/lib/python3.11/site-packages (from torch) (2024.6.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch)\n",
      "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.5.1 (from torch)\n",
      "  Downloading triton-3.5.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Downloading torch-2.9.1-cp311-cp311-manylinux_2_28_x86_64.whl (899.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.8/899.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:12\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:06\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:05\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m703.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:09\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.5.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.4/170.4 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.24.1-cp311-cp311-manylinux_2_28_x86_64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=6c843311aec37fc5b4e8d530323c4049f72601982d6bbdec872ad1a8a3db3fbb\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
      "Successfully built wget\n",
      "Installing collected packages: wget, nvidia-cusparselt-cu12, typing-extensions, triton, sympy, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.8.0\n",
      "    Uninstalling typing_extensions-4.8.0:\n",
      "      Successfully uninstalled typing_extensions-4.8.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12\n",
      "    Uninstalling sympy-1.12:\n",
      "      Successfully uninstalled sympy-1.12\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.28.3\n",
      "    Uninstalling nvidia-nccl-cu12-2.28.3:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.28.3\n",
      "Successfully installed filelock-3.20.0 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 sympy-1.14.0 torch-2.9.1 torchvision-0.24.1 triton-3.5.1 typing-extensions-4.15.0 wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision numpy wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c27aa7a-d0cc-44fd-8f35-cc93d8e0517a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. SETUP & REPRODUCIBILITY\n",
    "# Setting seeds for reproducibility as requested in the homework\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Ensure deterministic behavior for CuDNN\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e86dd6-495a-4ad8-9340-4fe2d49feef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eac5862-f692-4d8d-9a31-633bb158f9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data...\n",
      "--2025-12-02 19:26:46--  https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://release-assets.githubusercontent.com/github-production-release-asset/405934815/e712cf72-f851-44e0-9c05-e711624af985?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-02T20%3A08%3A08Z&rscd=attachment%3B+filename%3Ddata.zip&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-02T19%3A08%3A02Z&ske=2025-12-02T20%3A08%3A08Z&sks=b&skv=2018-11-09&sig=ZZk%2F2h7gJBu8j79HtBbhFMWlrhkrwK9uU4pZJBKDepk%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDcwNTQwNywibmJmIjoxNzY0NzAzNjA3LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.JUs6oeVRNAi7MhkCJ3CnE7zKp4z3p2AAGEpFQIW0Ajg&response-content-disposition=attachment%3B%20filename%3Ddata.zip&response-content-type=application%2Foctet-stream [following]\n",
      "--2025-12-02 19:26:47--  https://release-assets.githubusercontent.com/github-production-release-asset/405934815/e712cf72-f851-44e0-9c05-e711624af985?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-02T20%3A08%3A08Z&rscd=attachment%3B+filename%3Ddata.zip&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-02T19%3A08%3A02Z&ske=2025-12-02T20%3A08%3A08Z&sks=b&skv=2018-11-09&sig=ZZk%2F2h7gJBu8j79HtBbhFMWlrhkrwK9uU4pZJBKDepk%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDcwNTQwNywibmJmIjoxNzY0NzAzNjA3LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.JUs6oeVRNAi7MhkCJ3CnE7zKp4z3p2AAGEpFQIW0Ajg&response-content-disposition=attachment%3B%20filename%3Ddata.zip&response-content-type=application%2Foctet-stream\n",
      "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 102516572 (98M) [application/octet-stream]\n",
      "Saving to: ‘data.zip’\n",
      "\n",
      "data.zip            100%[===================>]  97.77M  36.6MB/s    in 2.7s    \n",
      "\n",
      "2025-12-02 19:26:50 (36.6 MB/s) - ‘data.zip’ saved [102516572/102516572]\n",
      "\n",
      "Unzipping data...\n",
      "Data extracted!\n"
     ]
    }
   ],
   "source": [
    "# Check if data.zip exists, if not - download it\n",
    "if not os.path.exists('data.zip'):\n",
    "    print(\"Downloading data...\")\n",
    "    !wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\n",
    "\n",
    "# Unzip the data into the current directory\n",
    "if not os.path.exists('data'):\n",
    "    print(\"Unzipping data...\")\n",
    "    with zipfile.ZipFile('data.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('.')\n",
    "    print(\"Data extracted!\")\n",
    "else:\n",
    "    print(\"Data folder already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e22eb1a2-e9ee-4c1b-b4e4-4cd058ac8bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 20073473\n"
     ]
    }
   ],
   "source": [
    "class HairNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HairNet, self).__init__()\n",
    "        # Input shape: (3, 200, 200)\n",
    "        \n",
    "        # Convolutional Layer\n",
    "        # in_channels=3 (RGB), out_channels=32, kernel=3x3\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=0, stride=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Max Pooling Layer\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Shape calculation:\n",
    "        # 1. Conv2d: (W - F + 2P)/S + 1 \n",
    "        #    -> (200 - 3 + 0)/1 + 1 = 198\n",
    "        #    Output shape: (32, 198, 198)\n",
    "        # 2. MaxPool2d: 198 / 2 = 99\n",
    "        #    Output shape: (32, 99, 99)\n",
    "        # 3. Flatten size: 32 * 99 * 99 = 313,632\n",
    "        \n",
    "        self.fc1 = nn.Linear(32 * 99 * 99, 64)\n",
    "        self.fc2 = nn.Linear(64, 1) # Output layer (1 neuron for binary classification)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        # Flatten the output for the fully connected layer\n",
    "        x = torch.flatten(x, 1) \n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model to count parameters\n",
    "model = HairNet().to(device)\n",
    "\n",
    "# Question 2: Total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\") \n",
    "# Expected answer usually around 20073473"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1363657b-a753-4c94-8bab-07092ad603fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, criterion, epochs, history=None):\n",
    "    \"\"\"\n",
    "    Main training loop. \n",
    "    If 'history' is provided, it appends new metrics to it.\n",
    "    \"\"\"\n",
    "    if history is None:\n",
    "        history = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # --- Training Phase ---\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # Reshape labels to (batch_size, 1) and ensure float type\n",
    "            labels = labels.float().unsqueeze(1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            # Apply sigmoid for binary classification accuracy\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = correct_train / total_train\n",
    "        \n",
    "        history['loss'].append(epoch_loss)\n",
    "        history['acc'].append(epoch_acc)\n",
    "        \n",
    "        # --- Validation Phase ---\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                labels = labels.float().unsqueeze(1)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_running_loss += loss.item() * images.size(0)\n",
    "                predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "                \n",
    "        val_epoch_loss = val_running_loss / len(val_loader.dataset)\n",
    "        val_epoch_acc = correct_val / total_val\n",
    "        \n",
    "        history['val_loss'].append(val_epoch_loss)\n",
    "        history['val_acc'].append(val_epoch_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "              f\"Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f} | \"\n",
    "              f\"Val Loss: {val_epoch_loss:.4f} | Val Acc: {val_epoch_acc:.4f}\")\n",
    "        \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ce2f83f-93e0-48de-af57-b9b8e6d9e35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 1: Training WITHOUT Augmentation ---\n",
      "Epoch 1/10 | Loss: 0.6654 | Acc: 0.6262 | Val Loss: 0.6102 | Val Acc: 0.6617\n",
      "Epoch 2/10 | Loss: 0.5479 | Acc: 0.7087 | Val Loss: 0.6303 | Val Acc: 0.6468\n",
      "Epoch 3/10 | Loss: 0.4858 | Acc: 0.7638 | Val Loss: 0.6991 | Val Acc: 0.5970\n",
      "Epoch 4/10 | Loss: 0.4806 | Acc: 0.7650 | Val Loss: 0.6097 | Val Acc: 0.7015\n",
      "Epoch 5/10 | Loss: 0.4403 | Acc: 0.7863 | Val Loss: 0.6215 | Val Acc: 0.6517\n",
      "Epoch 6/10 | Loss: 0.3493 | Acc: 0.8500 | Val Loss: 0.6453 | Val Acc: 0.6716\n",
      "Epoch 7/10 | Loss: 0.3005 | Acc: 0.8775 | Val Loss: 0.6954 | Val Acc: 0.6816\n",
      "Epoch 8/10 | Loss: 0.2746 | Acc: 0.8950 | Val Loss: 0.6396 | Val Acc: 0.7264\n",
      "Epoch 9/10 | Loss: 0.2163 | Acc: 0.9187 | Val Loss: 0.6716 | Val Acc: 0.7065\n",
      "Epoch 10/10 | Loss: 0.1466 | Acc: 0.9563 | Val Loss: 0.7745 | Val Acc: 0.7114\n",
      "\n",
      "========================================\n",
      "Question 3 (Median Train Accuracy): 0.8181\n",
      "Question 4 (Standard Deviation of Train Loss): 0.1527\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Phase 1: Training WITHOUT Augmentation ---\")\n",
    "\n",
    "# 1. Re-initialize the model\n",
    "model = HairNet().to(device)\n",
    "\n",
    "# 2. Define Loss and Optimizer (Question 1: BCEWithLogitsLoss)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.8)\n",
    "\n",
    "# 3. Define Transforms (Basic normalization only)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 4. Prepare Datasets and Loaders\n",
    "train_dataset = datasets.ImageFolder('./data/train', transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder('./data/test', transform=train_transforms) # Test folder used for validation\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=20, shuffle=False, num_workers=2)\n",
    "\n",
    "# 5. Run Training\n",
    "history_phase1 = train_model(model, train_loader, val_loader, optimizer, criterion, epochs=10)\n",
    "\n",
    "# 6. Calculate Answers for Q3 & Q4\n",
    "median_acc = np.median(history_phase1['acc'])\n",
    "std_loss = np.std(history_phase1['loss'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"Question 3 (Median Train Accuracy): {median_acc:.4f}\")\n",
    "print(f\"Question 4 (Standard Deviation of Train Loss): {std_loss:.4f}\")\n",
    "print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac7cc20f-31e7-478c-8f76-a4c0c5b993c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Phase 2: Training WITH Augmentation ---\n",
      "Epoch 1/10 | Loss: 0.6820 | Acc: 0.6587 | Val Loss: 0.6043 | Val Acc: 0.6816\n",
      "Epoch 2/10 | Loss: 0.5393 | Acc: 0.7113 | Val Loss: 0.7068 | Val Acc: 0.6468\n",
      "Epoch 3/10 | Loss: 0.5190 | Acc: 0.7400 | Val Loss: 0.5641 | Val Acc: 0.6965\n",
      "Epoch 4/10 | Loss: 0.5407 | Acc: 0.7125 | Val Loss: 0.5927 | Val Acc: 0.7114\n",
      "Epoch 5/10 | Loss: 0.4818 | Acc: 0.7662 | Val Loss: 0.5380 | Val Acc: 0.7313\n",
      "Epoch 6/10 | Loss: 0.4880 | Acc: 0.7450 | Val Loss: 0.5159 | Val Acc: 0.7264\n",
      "Epoch 7/10 | Loss: 0.4934 | Acc: 0.7550 | Val Loss: 0.5079 | Val Acc: 0.7662\n",
      "Epoch 8/10 | Loss: 0.4860 | Acc: 0.7738 | Val Loss: 0.4994 | Val Acc: 0.7811\n",
      "Epoch 9/10 | Loss: 0.4443 | Acc: 0.7825 | Val Loss: 0.6461 | Val Acc: 0.6468\n",
      "Epoch 10/10 | Loss: 0.4532 | Acc: 0.7900 | Val Loss: 0.5438 | Val Acc: 0.7264\n",
      "\n",
      "========================================\n",
      "Question 5 (Mean Validation Loss with Augmentation): 0.5719\n",
      "Question 6 (Avg Validation Accuracy, last 5 epochs): 0.7294\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Phase 2: Training WITH Augmentation ---\")\n",
    "\n",
    "# 1. Define NEW Transforms with Augmentation\n",
    "train_transforms_aug = transforms.Compose([\n",
    "    transforms.RandomRotation(50),\n",
    "    transforms.RandomResizedCrop(200, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize((200, 200)), # Ensure final size is correct\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 2. Re-create Training Dataset and Loader with new transforms\n",
    "# Note: We do NOT re-create the model. We continue training the existing one.\n",
    "train_dataset_aug = datasets.ImageFolder('./data/train', transform=train_transforms_aug)\n",
    "train_loader_aug = DataLoader(train_dataset_aug, batch_size=20, shuffle=True, num_workers=2)\n",
    "\n",
    "# 3. Continue Training\n",
    "# We pass 'history_phase1' so the new metrics are appended to it\n",
    "history_phase2 = train_model(model, train_loader_aug, val_loader, optimizer, criterion, epochs=10, history=history_phase1)\n",
    "\n",
    "# 4. Calculate Answers for Q5 & Q6\n",
    "# We need to look at the metrics from the SECOND phase (epochs 11-20)\n",
    "# Since 'history' is a single list now containing 20 epochs, we slice the last 10 entries.\n",
    "\n",
    "aug_val_losses = history_phase2['val_loss'][10:]  # Epochs 11-20\n",
    "aug_val_accs = history_phase2['val_acc'][10:]    # Epochs 11-20\n",
    "\n",
    "# Question 5: Mean of test (val) loss for ALL epochs trained with augmentations\n",
    "mean_test_loss_aug = np.mean(aug_val_losses)\n",
    "\n",
    "# Question 6: Average of test (val) accuracy for the LAST 5 epochs (epochs 16-20)\n",
    "# In our slice [10:], indices 5,6,7,8,9 correspond to the last 5 epochs.\n",
    "avg_test_acc_last_5 = np.mean(aug_val_accs[5:])\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"Question 5 (Mean Validation Loss with Augmentation): {mean_test_loss_aug:.4f}\")\n",
    "print(f\"Question 6 (Avg Validation Accuracy, last 5 epochs): {avg_test_acc_last_5:.4f}\")\n",
    "print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a96fc4b-832a-4ed2-9019-21398ec7d847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5c6c28-ca59-40af-8e9f-e72b1bcabca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
