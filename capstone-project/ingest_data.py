import os
import boto3
from kaggle.api.kaggle_api_extended import KaggleApi
from botocore.exceptions import ClientError
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor
import shutil

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø (–ë–µ—Ä–µ–º –∏–∑ ENV, –∫–∞–∫ –≤ —Ç–≤–æ–µ–º —Å–∫—Ä–∏–ø—Ç–µ) ---
# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ MinIO
MINIO_ENDPOINT = os.getenv("MINIO_S3_ENDPOINT_URL", "https://s3.k8s.dgoi.ru")
ACCESS_KEY = os.getenv("MINIO_ACCESS_KEY", "zOw8x0hri01phOFO5POr")
SECRET_KEY = os.getenv("MINIO_SECRET_KEY", "zi5HjnYiWZhn07IjrwpvL3wZoJ72JrR4YuyR63Nr")
BUCKET_NAME = os.getenv("MINIO_BUCKET_NAME", "leukemia-data")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Kaggle Dataset
DATASET_NAME = "andrewmvd/leukemia-classification" # C-NMC dataset
LOCAL_CACHE_DIR = os.getenv("LOCAL_CACHE_DIR", "./temp_data")

def get_s3_client():
    return boto3.client('s3',
                        endpoint_url=MINIO_ENDPOINT,
                        aws_access_key_id=ACCESS_KEY,
                        aws_secret_access_key=SECRET_KEY,
                        verify=False)

def check_bucket_exists(s3, bucket_name):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –±–∞–∫–µ—Ç–∞ –∏ —Å–æ–∑–¥–∞–µ—Ç –µ–≥–æ, –µ—Å–ª–∏ –Ω–µ—Ç."""
    try:
        s3.head_bucket(Bucket=bucket_name)
        print(f"‚úÖ Bucket '{bucket_name}' exists.")
    except ClientError:
        print(f"‚ö†Ô∏è Bucket '{bucket_name}' not found. Creating...")
        try:
            s3.create_bucket(Bucket=bucket_name)
            print(f"‚úÖ Bucket '{bucket_name}' created successfully.")
        except Exception as e:
            print(f"‚ùå Critical Error creating bucket: {e}")
            exit(1)

def is_dataset_in_minio(s3, bucket_name):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ —É–∂–µ –¥–∞–Ω–Ω—ã–µ –≤ MinIO (–ø–æ –Ω–∞–ª–∏—á–∏—é –ø–∞–ø–∫–∏ validation)."""
    # C-NMC —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: C-NMC_Leukemia/training_data/...
    # –ü—Ä–æ–≤–µ—Ä–∏–º –Ω–∞–ª–∏—á–∏–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–∑–∞–ª–∏–≤–∞—Ç—å –∑—Ä—è
    result = s3.list_objects_v2(Bucket=bucket_name, Prefix="C-NMC_Leukemia/", MaxKeys=1)
    return 'Contents' in result

def download_dataset_from_kaggle():
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –∏ —Ä–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –ª–æ–∫–∞–ª—å–Ω–æ."""
    print("‚¨áÔ∏è Downloading dataset from Kaggle...")
    api = KaggleApi()
    api.authenticate()

    if not os.path.exists(LOCAL_CACHE_DIR):
        os.makedirs(LOCAL_CACHE_DIR)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞, —Å–∫–∞—á–∞–Ω–æ –ª–∏ —É–∂–µ
    if os.path.exists(os.path.join(LOCAL_CACHE_DIR, "C-NMC_Leukemia")):
        print("‚úÖ Dataset already downloaded locally.")
        return

    api.dataset_download_files(DATASET_NAME, path=LOCAL_CACHE_DIR, unzip=True)
    print("‚úÖ Download and extraction complete.")

def upload_file_worker(args):
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—É–ª–∞ –ø–æ—Ç–æ–∫–æ–≤."""
    s3_client, file_path, bucket, object_name = args
    try:
        s3_client.upload_file(file_path, bucket, object_name)
    except Exception as e:
        return f"Error uploading {object_name}: {e}"
    return None

def upload_to_minio(s3):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª—ã –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–π –ø–∞–ø–∫–∏ –≤ MinIO –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ."""
    print("üöÄ Starting upload to MinIO...")
    
    files_to_upload = []
    # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø—Ä–æ—Ö–æ–¥–∏–º –ø–æ —Å–∫–∞—á–∞–Ω–Ω–æ–π –ø–∞–ø–∫–µ
    for root, dirs, files in os.walk(LOCAL_CACHE_DIR):
        for file in files:
            local_path = os.path.join(root, file)
            # –£–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å temp_data –∏–∑ –ø—É—Ç–∏ –≤ –±–∞–∫–µ—Ç–µ
            relative_path = os.path.relpath(local_path, LOCAL_CACHE_DIR)
            # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø—Ä–µ—Ñ–∏–∫—Å –≤–µ—Ä—Å–∏–∏, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ (–∫–∞–∫ –≤ —Ç–≤–æ–µ–º —Å–∫—Ä–∏–ø—Ç–µ PROJECT_ROOT)
            # object_name = f"raw_data/{relative_path}" 
            object_name = relative_path 
            files_to_upload.append((local_path, object_name))

    print(f"üì¶ Found {len(files_to_upload)} files to upload.")

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º ThreadPoolExecutor –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
    # –ü–µ—Ä–µ–¥–∞–µ–º s3 client –≤ –∫–∞–∂–¥—ã–π –ø–æ—Ç–æ–∫ (boto3 client –ø–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–µ–Ω)
    
    with ThreadPoolExecutor(max_workers=20) as executor:
        # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á
        futures = []
        for local_path, object_name in files_to_upload:
            futures.append(executor.submit(upload_file_worker, (s3, local_path, BUCKET_NAME, object_name)))
        
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        for future in tqdm(futures, total=len(files_to_upload), unit="file"):
            result = future.result()
            if result:
                print(result) # –ü–µ—á–∞—Ç–∞–µ–º –æ—à–∏–±–∫—É, –µ—Å–ª–∏ –±—ã–ª–∞

    print("‚úÖ Upload to MinIO complete!")

if __name__ == "__main__":
    print(f"üîå Connecting to MinIO at {MINIO_ENDPOINT}...")
    s3 = get_s3_client()
    
    check_bucket_exists(s3, BUCKET_NAME)
    
    if is_dataset_in_minio(s3, BUCKET_NAME):
        print("‚ú® Dataset already exists in MinIO. Skipping download & upload.")
        # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Ñ–ª–∞–≥ --force –¥–ª—è –ø–µ—Ä–µ–∑–∞–ª–∏–≤–∫–∏
    else:
        download_dataset_from_kaggle()
        upload_to_minio(s3)
        
        # –û—á–∏—Å—Ç–∫–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        # print("Cleaning up local cache...")
        # shutil.rmtree(LOCAL_CACHE_DIR)
        print("üéâ Done! Data is ready in MinIO.")
